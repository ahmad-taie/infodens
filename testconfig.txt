[Input]
# params are parsed after ':' or '='

train file : data/sent2.train
train classes:  data/sent2_classes.train
test file : data/sent2.test
test classes:  data/sent2_classes.test
#predict file : data/sent2.test

#train feats: feats2_trainFeats.libsvm
#test feats: feats2_testFeats.libsvm

training corpus: data/30k.literature.orig_tran.low.en
language : eng

[Output]

#classifier report: report1.txt
#output features: feats2 libsvm
#persist models: testClass.skl

[Settings]
#srilm : srilm-1.7.2/bin/i686-m64
kenlm : /home/gilani/Documents/Github/kenlm/build/bin/
threads : 4

[Classifiers]

#Random_forest
#Decision_tree
#Ada_boost
#Ensemble
#SVC_linear: -rank 5
#Random_forest: -rank 10
#SVR_linear
#Logistic_regression
#SVC_linear
#MLP_classifier: -hidden_layers 100
Keras_MLP: -hidden_layers 100,10 -epochs 4

[Features]
#1
# This is a comment
#2: a,b,c,d
#3: -pos_tags JJ,JJR,JJS,NN,NNP,NNS,RB,RBR,RBS,VB,VBD,VBG,VBN,VBP,VBZ -pos_train data/sent2.train
4: -ngram 1 -cutoff 2
#4: -ngram 2 -cutoff 5
#4: -ngram 3 -cutoff 1
#5: -ngram 1 -cutoff 10 -proc_train data/pos_sent2.train -proc_test data/pos_sent2.test
#5: -ngram 1 -cutoff 10
#6: -ngram 1 -cutoff 10
#7: -ngram 1 -cutoff 10
#10
#11
#12: -pos_tags JJ,JJR,JJS,NN,NNP,NNS,RB,RBR,RBS,VB,VBD,VBG,VBN,VBP,VBZ -pos_train data/pos_sent2.train -pos_test data/pos_sent2.test
#33:100
#33:GoogleNews-vectors-negative300.bin
#34
#17: -ngram 3 -lm data/30k.literature.orig_tran.low.en_langModel3.lm
#17: -ngram 3
#18:-pos_corpus data/testSent2.txt_tagged_Input.txt
#19: -ngram 1 -cutoff 10 -n_quantiles 4
#20: -ngram 3 -lm data/testSent2.txt_langModel3.lm
#21 : -pos_corpus data/testSent2.txt_tagged_Input.txt
#77: -ngram 5
#801: -dim 20 -epochs 10 -wordNgrams 2
